{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "040364701eea834f1b18fc785dd59cb5",
     "grade": false,
     "grade_id": "cell-c4be203e1da1aa63",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Mandatory Assignment 2\n",
    "\n",
    "This is the last of three mandatory assignments which must be completed during the course. Note that you only need to pass 2 out of 3 assignments to be eligible for the exam.\n",
    "\n",
    "First some practical pieces of information:\n",
    "\n",
    "* When is the assignment due?: **23:59, Friday, August 12, 2022.**\n",
    "* Should i work with my group?: **Yes**. In particular, you should **only hand in 1 assignment per group and in a comment on Absalon write your group number and all group members**. \n",
    "\n",
    "The assignment consists of problems from the exercise sets that you have solved so far, problems from the exercises that have been modified a little to better suit the structure of the assignment and finally also new problems not seen in the exercises. \n",
    "\n",
    "**Note**: \n",
    "- It is important that you submit your edited version of this [notebook](https://fileinfo.com/extension/ipynb#:~:text=An%20IPYNB%20file%20is%20a,Python%20language%20and%20their%20data.) as a .ipynb file and nothing else. Do not copy your answers into another notebook that you have made. \n",
    "- **DON'T** delete the (possibly) empty non-editable cells below (most) questions. Those are tests used by the `nbgrader` software to grade the assignment.\n",
    "- It is recommended to clone our [github repository](https://github.com/isdsucph/isds2022) and copy the entire `assignment2` folder to somewhere on your computer and complete the assignment in this folder.\n",
    "- It is good practice to always restart your notebook and run all cells before submitting or delivering your notebook to somebody else. This is to make sure that all cells run without raising any errors breaking the flow of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# RUN THIS CELL AND USE THE DATA TO SOLVE THE NEXT EXERCISES #\n",
    "##############################################################\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "iris = sns.load_dataset('iris')\n",
    "iris = (\n",
    "    iris.query(\"species == 'virginica' | species == 'versicolor'\")\n",
    "    .sample(frac = 1, random_state = 3)\n",
    ")\n",
    "X = np.array(iris[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']])\n",
    "y = np.array(iris['species'].map({'virginica': 1, 'versicolor': -1}))\n",
    "\n",
    "# EDA before modelling:\n",
    "# Do the two species look perfectly linear seperable in any of the plots?\n",
    "# (If they are not linear seperable the consequence is that the Perceptron algorithm\n",
    "# won't converge, see Raschka's PML book)\n",
    "ax = sns.pairplot(iris, hue=\"species\", palette=\"husl\", diag_kws = {'shade': False})\n",
    "ax.fig.subplots_adjust(top=0.95)\n",
    "ax.fig.suptitle('Pairplot of features for the virginica and versicolor species', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# A very simple deterministic test-train split \n",
    "Xtrain = X[:70]\n",
    "ytrain = y[:70]\n",
    "\n",
    "Xtest = X[70:]\n",
    "ytest = y[70:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "89e0f3447d463c9af477828e0fa85e7a",
     "grade": false,
     "grade_id": "cell-2549517e368b0847",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problems from Exercise Set 10:\n",
    "\n",
    "> **Ex. 10.1.5:** Write a function named `perceptronEpoch` whichs loops over the training data (both X and y) using `zip`. For each row in the data, update the weights according to the perceptron rule (remember to update the bias in `w[0]`!). Set $\\eta = 0.1$.\n",
    ">\n",
    "> Make sure the loop stores the total number of prediction errors encountered underways in the loop by creating an `int` which is incremented whenever you update the weights. \n",
    ">\n",
    "> You can complete the function with the docstring below if you like or just delete it and paste in your own.\n",
    ">> _Hint:_ your function should return the updated weights, as well as the number of errors made by the perceptron.\n",
    ">\n",
    ">> _Hint:_ The following code block implements the function in _pseudo_code (it wont run, but serves to communicate the functionality).\n",
    ">> ```\n",
    ">> function perceptronEpoch(X, y, W, eta):\n",
    ">>    set errors = 0\n",
    ">>\n",
    ">>    for each pair xi, yi in zip(X,y) do:\n",
    ">>        set update = eta * (yi - predict(xi, W))\n",
    ">>        set W[1:] = W[1:] + update * xi\n",
    ">>        set W[0] = W[0] + update\n",
    ">>        set errors = errors + int(update != 0) \n",
    ">>\n",
    ">>    return W, errors\n",
    ">> ```\n",
    ">\n",
    "> *Bonus:* If you completed the previous bonus exercise (for 10.1.4), calculate the accuracy on training data using the updated weights as input in the predict function. Any progress yet?\n",
    "\n",
    "\n",
    "You can use the following functions:\n",
    "\n",
    "```python\n",
    "def random_weights(location=0.0, scale=0.01, seed=1):\n",
    "    # Init random number generator\n",
    "    rgen = np.random.RandomState(seed)\n",
    "    w = rgen.normal(loc=location, scale=scale, size=1 + X.shape[1])\n",
    "    \n",
    "    return w\n",
    "\n",
    "def net_input(X, W): \n",
    "    return np.dot(X, W[1:]) + W[0]   # Linear product X'W + bias\n",
    "\n",
    "\n",
    "def predict(X, W):\n",
    "    linProd = net_input(X, W)\n",
    "    return np.where(linProd >= 0.0, 1, -1)    # 1(linProd > 0)\n",
    "```\n",
    "\n",
    ">\n",
    "> Make sure your `perceptronEpoch` function takes the arguments `X, y, W, eta`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8fdf4acbe09c52de7e66f328673d291",
     "grade": false,
     "grade_id": "ex_10_1_5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def perceptronEpoch(X, y, W, eta=0.1):\n",
    "    \"\"\"Computes an epoch of training for the Perceptron algorithm.\n",
    "    \n",
    "    Args:\n",
    "        X (np.ndarray): \n",
    "            Feature data of dimension (N, k) where k is the number \n",
    "            of features.\n",
    "        y (np.ndarray):\n",
    "            Target vector of dimension (N, ).\n",
    "        W (np.ndarray):\n",
    "            Weight vector of dimension (k + 1, ) where the first\n",
    "            parameter is the bias term.\n",
    "        eta (float): Learning rate of the algorithm, defaults to 0.1.\n",
    "    \n",
    "    Returns:\n",
    "        tuple[np.ndarray, int]: \n",
    "            Updated weight wector and number of errors made \n",
    "            for the epoch of training.\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a62133013d2c649371d6ec8f49fca629",
     "grade": true,
     "grade_id": "ex_10_1_5_test",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e940d79272bb068d5bea4fdecd8c5be8",
     "grade": false,
     "grade_id": "cell-59488e40ebf2f946",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 10.1.6:** Write a function named `Perceptron` which repeat the updating procedure (calls the function) you constructed in 10.1.5 for `n_iter` times by packing the whole thing in a loop. Make sure you store the number of errors in each iteration in a list. \n",
    ">\n",
    "> Plot the total errors after each iteration in a graph with the number of epochs along the x-axis and errors along the y-axis.\n",
    ">\n",
    ">> _Hint:_ Make sure you dont reset the weights after each iteration.\n",
    ">\n",
    ">> _Hint:_ Once again some pseudocode:\n",
    ">> ```\n",
    ">> function Perceptron(X, y, n_iter):\n",
    ">>     set eta = 0.1\n",
    ">>     set weights = random_weights()\n",
    ">>     set errorseq = list()\n",
    ">>\n",
    ">>     for each _ in range(n_iter):\n",
    ">>         weights, e = f(X, y, W, eta) \n",
    ">>         errorseq.append(e)\n",
    ">>\n",
    ">>     return weights, errorseq\n",
    ">> ```\n",
    "\n",
    "Please make sure that your function is named `Perceptron` and takes the arguments `X, y, n_iter, eta`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ef4002b42125fae832a3943b4dce73d",
     "grade": false,
     "grade_id": "ex_10_1_6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f89534ff363bf0f864c8be7429e0eb5d",
     "grade": true,
     "grade_id": "ex_10_1_6_test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "287e32174bd33a71246c01ed5bd7c944",
     "grade": false,
     "grade_id": "cell-99668841f5921403",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problems from Exercise Set 11:\n",
    "\n",
    "### First part of Exercise Set 11: Implementing and evaluating the gradient decent for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# RUN THIS CELL AND USE THE DATA TO SOLVE THE NEXT EXERCISES #\n",
    "##############################################################\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.exceptions import DataConversionWarning; import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "# Load the example tips dataset\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "tips_num = pd.get_dummies(tips, drop_first=True)  # Get dummies \n",
    "\n",
    "# Define feature matrix X and target vector y \n",
    "X = tips_num.drop('tip', axis = 1)\n",
    "y = tips_num['tip']\n",
    "\n",
    "\n",
    "## NOTE: It is important that the random_state parameter is set equal to 1\n",
    "# to ensure that the same sequence of random numbers are generated as in\n",
    "# the solution notebook.\n",
    "\n",
    "# Split data into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y, \n",
    "    test_size=.5,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# Standardize data - note that we only fit the standard scaler\n",
    "# on X_train and use it on X_train, X_test.\n",
    "norm_scaler = StandardScaler().fit(X_train) \n",
    "X_train = norm_scaler.transform(X_train) \n",
    "X_test = norm_scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c6ceb68e8848e5d5d9ae43c5971d9acb",
     "grade": false,
     "grade_id": "cell-3582848e2d16da20",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 11.1.5**: Make a function to update the weights given input target `y`, input features `X` and input weights `w` as well as learning rate, $\\eta$, i.e. greek `eta`. Name the function `update_weight`. You should use matrix multiplication.\n",
    "\n",
    "\n",
    "You can use the following functions inside `update_weight`:\n",
    "\n",
    "```python\n",
    "def net_input(X, w):    \n",
    "    ''' Computes the matrix product between X and w. Note that\n",
    "    X is assumed not to contain a bias/intercept column.'''\n",
    "    # We have to add w_[0] separately because this is the constant term.\n",
    "    # We could also have added a constant term to the X matrix to avoid\n",
    "    # splitting the dot product up as below.\n",
    "    return np.dot(X, w[1:]) + w[0]   \n",
    "                                        \n",
    "\n",
    "def compute_error(y, X, w):\n",
    "    return y - net_input(X, w)\n",
    "    \n",
    "```\n",
    "\n",
    ">\n",
    "> Make sure your function takes the arguments `X, y, W, eta`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc0435fb0fbd7b43b24b0f7bfdbbfc50",
     "grade": true,
     "grade_id": "ex_11_1_5_test",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ab677018f23e2a551934f8f341fb7b7f",
     "grade": false,
     "grade_id": "cell-f840d5f2932b1d25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 11.1.6**: Use the code below to initialize the weights in the variable `w` at zero given feature set `X`. Notice how we include an extra weight that includes the bias term. Set the learning rate `eta` to 0.001. Make a loop with 50 iterations where you iteratively apply your weight updating function. \n",
    "\n",
    ">```python\n",
    "w = np.zeros(1 + X.shape[1])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ce31cfd31b3acccea4a0c9b3f49172a",
     "grade": false,
     "grade_id": "ex_11_1_6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dab6cc20e0b180c52bb7f5ab8f8ec1cb",
     "grade": true,
     "grade_id": "ex_11_1_6_test",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## This is a test cell, please don't delete it! \n",
    "## If it doesn't raise an error when run your code works!\n",
    "assert round(np.sum(w)) == 4\n",
    "assert any(np.round(w, 2) == [ 2.93,  0.89,  0.1 ,  0.07,  0.08,  0.05,  0.  , -0.04, -0.02])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "19c16efae0ac7996983cee251e4cd976",
     "grade": false,
     "grade_id": "cell-a6898fa843a456ad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Third part of Exercise Set 11: Modelling houseprices\n",
    "In this example we will try to predict houseprices using a lot of variable (or features as they are called in Machine Learning). We are going to work with Kaggle's dataset on house prices, see information [here](https://www.kaggle.com/c/house-prices-advanced-regression-techniques), which also is to be found in `sklearn.datasets`. Kaggle is an organization that hosts competitions in building predictive models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "#RUN THIS CELL AND USE THE DATA TO SOLVE THE NEXT EXERCISES#\n",
    "############################################################\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cal_house = fetch_california_housing()\n",
    "X = pd.DataFrame(data=cal_house[\"data\"], columns=cal_house[\"feature_names\"]).iloc[\n",
    "    :, :-2\n",
    "]\n",
    "y = cal_house[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=1\n",
    ")  # note random_state=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9f6f5dcc884be1ba9df7ab3978e50dda",
     "grade": false,
     "grade_id": "cell-6f125b68cf8cebb7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex.11.3.1**: Generate interactions between all features to third degree, make sure you **exclude** the bias/intercept term. How many variables are there? Will OLS fail? Write 2 sentences. \n",
    ">\n",
    "> After making interactions rescale the features to have zero mean, unit std. deviation. Should you use the distribution of the training data to rescale the test data?  Write 1 sentence. \n",
    ">\n",
    ">> *Hint 1*: Try importing `PolynomialFeatures` from `sklearn.preprocessing`\n",
    ">\n",
    ">> *Hint 2*: If in doubt about which distribution to scale, you may read [this post](https://stats.stackexchange.com/questions/174823/how-to-apply-standardization-normalization-to-train-and-testset-if-prediction-i).\n",
    "\n",
    "Name you transformed training data set `X_train2` and your test data set `X_test2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42bb99fbca7f54fd2d31dda42b9c0d42",
     "grade": false,
     "grade_id": "ex_11_2_1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "021dff39b22126ada1c5f641a427df2d",
     "grade": true,
     "grade_id": "ex_11_2_1_test",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6e6090533993c628b5920f414b23a20f",
     "grade": false,
     "grade_id": "cell-e28611963fcc9e39",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex.11.3.2**: Construct a list of 20 $\\lambda$ values in the range from $10^{-4}$ to $10^4$ to be used in the Lasso model. For each $\\lambda$ estimate the Lasso model on the rescaled train data, calculate the _Root Mean_ Squared Error (RMSE) for the rescaled train data, `X_train2`, and the _Root Mean_ Squared Error (RMSE) for the rescaled test data, `X_test2`. For each iteration store the given $\\lambda$ and the calculated RMSEs for the rescaled train and test data in a list named `output`. \n",
    "\n",
    "> *Hint*: use `np.logspace(-4, 4, 20)` to create the list of lambdas to loop. \n",
    "\n",
    "> *Hint*: You can use the following code from scikit-learn to compute the _mean_ squared error.\n",
    "```python\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "mse(y_true, y_pred)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f99d24101881a1dabc22d222334de44e",
     "grade": false,
     "grade_id": "ex_11_2_2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "304044dfdb889576c16f6cd7a11a3fe1",
     "grade": true,
     "grade_id": "ex_11_2_2_test",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## This is a test cell, please don't delete it! \n",
    "## If it doesn't raise an error when run your code works!\n",
    "assert any(np.sort(np.round(np.mean(output, axis=0))) == [1.0, 2.0, 806.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "90fcbe6a13b2ec80d996b2a4d9e0cbc1",
     "grade": false,
     "grade_id": "cell-620ee97ca95a84f4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex.11.3.3**: Make a plot with the lambdas on the x-axis and the RMSE measures on the y-axis. What happens to RMSE for train and test data as $\\lambda$ increases? The x-axis should be log scaled. Which one are we interested in minimizing? \n",
    "\n",
    "> Bonus: Can you find the lambda that gives the lowest MSE-test score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2815a795b369dd07baae6b28abf23751",
     "grade": true,
     "grade_id": "ex_11_2_3",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f90c196050f707712ca773ae22e88d96",
     "grade": false,
     "grade_id": "cell-df90d5afe2967903",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problems from Exercise Set 12:\n",
    "\n",
    "> **Ex. 12.2.3:**\n",
    "Run a Lasso regression using the Pipeline from `Ex 12.2.2` which is given in the code cell below. In the outer loop searching through the 12 lambda values as specified below. \n",
    "In the inner loop make *5 fold cross validation* on the selected model and store the average MSE for each fold. Which lambda, from the selection below, gives the lowest test MSE?\n",
    " ```python \n",
    "lambdas =  np.logspace(-4, 4, 12)\n",
    "```\n",
    " *Hint:* `KFold` in `sklearn.model_selection` may be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c49fe6ec61ae7f604752877cba10768",
     "grade": true,
     "grade_id": "ex_12_1_4",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Pipeline from Ex. 12.2.2\n",
    "pipe_lasso = make_pipeline(\n",
    "    PolynomialFeatures(degree=3, include_bias=False),\n",
    "    StandardScaler(),\n",
    "    Lasso(random_state=1),\n",
    ")\n",
    "\n",
    "# The feature matrix X and target vector y are defined\n",
    "# in the code cell \"Second part of Exercise Set 11: Modelling houseprices\".\n",
    "\n",
    "# Split X, y into development (2/3) and test data (1/3).\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X, y, test_size=(1 / 3), random_state=1)\n",
    "\n",
    "lambdas = np.logspace(-4, 4, 12)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c18e9b95c3a8b576eaab35c2c69be374",
     "grade": false,
     "grade_id": "cell-878b42b675168f8a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## New problems in Assignment 2\n",
    "\n",
    "> One of the fastest ways to extract and structure relevant information from text is by using regular expressions (regexes). In the following exercises we will leverage the power of regexes to extract relevant information from a text snippet of a meeting in the Danish parliament taken from [here](https://www.folketingstidende.dk/samling/20211/salen/M41/20211_M41_referat.pdf). \n",
    "\n",
    "> The text snippet is located in a txt file named `parliamentmeeting.txt` in the `data` folder inside this assignment repository. The snippet has been extracted from the pdf file using the `pdfreader` [package]([link](https://pdfreader.readthedocs.io/en/latest/)). The snippet consists of all text from page 2-4 (inclusive) of the original pdf file.\n",
    ">\n",
    "> Our goal is to extract all speakers with their corresponding speech from the text snippet. \n",
    ">\n",
    "> **Ex. N.1**: Write a regex that matches \n",
    "> - The time that the speaker started to speak\n",
    "> - A possible title in parenthesis\n",
    "> - The name of the speaker\n",
    "> - The political affiliation of the speaker\n",
    "> - An ending colon\n",
    "> \n",
    ">  from the strings in the list `TEST_STRINGS` defined below. The regex should be stored in a variable named `re_find_speakers`. \n",
    "> \n",
    "> \n",
    "> When applied to the strings in the list it should yield the output below:\n",
    "\n",
    "```python\n",
    "# Loop through each string and search for a match with the regex\n",
    "for string in TEST_STRINGS:  \n",
    "    print(re_find_speakers.search(string))\n",
    "    \n",
    "## Output:\n",
    "# <re.Match object; span=(20, 68), match='Kl. 09:03(Ordfører)Christian Rabjerg Madsen (S):'>\n",
    "# <re.Match object; span=(20, 63), match='Kl. 09:12Formanden (Henrik Dam Kristensen):'>\n",
    "# <re.Match object; span=(20, 53), match='Kl. 09:12Troels Lund Poulsen (V):'>\n",
    "# <re.Match object; span=(20, 63), match='Kl. 09:13Formanden (Henrik Dam Kristensen):'>\n",
    "```\n",
    "- *Hint 1:* To avoid drowning in regex expressions use the `re.VERBOSE` flag. This allows one to split a regex on multiple lines and write comments to each specific expression. See the Python regex tutorial [here](https://docs.python.org/3/howto/regex.html)\n",
    "- *Hint 2:* [Capture groups and named capture groups](https://www.pythontutorial.net/python-regex/python-regex-capturing-group/) might be a help to organize your regex\n",
    "- *Hint 3:* Consult [this](https://www.debuggex.com/cheatsheet/regex/python) cheatsheet for help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the re module used to construct and use regexes in python\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "038068be24ea85243adfc568af0201e7",
     "grade": false,
     "grade_id": "N1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "TEST_STRINGS = [\n",
    "    \", Socialdemokratiet.Kl. 09:03(Ordfører)Christian Rabjerg Madsen (S):Tak for det. For to \", \n",
    "    \"det og glædelig jul.Kl. 09:12Formanden (Henrik Dam Kristensen):Ja, det varer lidt, \", \n",
    "    \"nd Poulsen, Venstre.Kl. 09:12Troels Lund Poulsen (V):Tak for det. Tak for\", \n",
    "    \"r Socialdemokratiet?Kl. 09:13Formanden (Henrik Dam Kristensen):Ordføreren, værsgo.K\", \n",
    "]\n",
    "\n",
    "re_find_speakers = re.compile(r\"\"\"\"\"\")  # Write your regex inside the string\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "599f9260bfb0583b605c19a03d236ab9",
     "grade": true,
     "grade_id": "N1-test",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## This is a test cell, please don't delete it! \n",
    "## If it doesn't raise an error when run your code works!\n",
    "\n",
    "# Get matches for each test string\n",
    "matches = [re_find_speakers.search(string) for string in TEST_STRINGS]\n",
    "\n",
    "# Matched spans\n",
    "spans = [match.span() for match in matches]\n",
    "assert spans == [(20, 68), (20, 63), (20, 53), (20, 63)]\n",
    "\n",
    "# Matched strings\n",
    "matched_strings = [match.group(0) for match in matches]\n",
    "assert matched_strings == [\n",
    "    'Kl. 09:03(Ordfører)Christian Rabjerg Madsen (S):',\n",
    "    'Kl. 09:12Formanden (Henrik Dam Kristensen):',\n",
    "    'Kl. 09:12Troels Lund Poulsen (V):',\n",
    "    'Kl. 09:13Formanden (Henrik Dam Kristensen):'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "70f2407febebb76eb57819d0bc2309ee",
     "grade": false,
     "grade_id": "cell-4ca1929e2677ea7e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. N.2**: Load the `parliamentmeeting.txt` file from the `data` folder into a variable named `parliament_meeting`. Next, apply your regex `re_find_speakers` to the text snippet stored in `parliament_meeting` using the `finditer` method of the regex. Use a list comprehension to store each match in a list named `meeting`. You should write something like:\n",
    "\n",
    "```python\n",
    "matches = [match for match in re_find_speakers.finditer(parliament_meeting)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "30226a9fa50e83f515ea731f564c1487",
     "grade": false,
     "grade_id": "N2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "261552ade309219c6ec42587c18745d1",
     "grade": true,
     "grade_id": "N2-test",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## This is a test cell, please don't delete it! \n",
    "## If it doesn't raise an error when run your code works!\n",
    "matches = [match for match in re_find_speakers.finditer(parliament_meeting)]\n",
    "spans = [match.span() for match in matches]\n",
    "assert spans == [\n",
    "    (61, 109),\n",
    "    (8641, 8684),\n",
    "    (8880, 8913),\n",
    "    (9983, 10026),\n",
    "    (10045, 10083),\n",
    "    (11136, 11179),\n",
    "    (11211, 11244),\n",
    "    (12435, 12478),\n",
    "    (12560, 12598),\n",
    "    (13161, 13204),\n",
    "    (13253, 13284),\n",
    "    (14683, 14726),\n",
    "    (14745, 14783),\n",
    "    (16039, 16082),\n",
    "    (16111, 16142),\n",
    "    (16975, 17018),\n",
    "    (17037, 17075),\n",
    "    (17843, 17886),\n",
    "    (17915, 17950),\n",
    "    (18911, 18954),\n",
    "    (18973, 19011),\n",
    "    (20253, 20296),\n",
    "]\n",
    "\n",
    "names = [match.group() for match in matches]\n",
    "assert names == [\n",
    "    \"Kl. 09:03(Ordfører)Christian Rabjerg Madsen (S):\",\n",
    "    \"Kl. 09:12Formanden (Henrik Dam Kristensen):\",\n",
    "    \"Kl. 09:12Troels Lund Poulsen (V):\",\n",
    "    \"Kl. 09:13Formanden (Henrik Dam Kristensen):\",\n",
    "    \"Kl. 09:14Christian Rabjerg Madsen (S):\",\n",
    "    \"Kl. 09:15Formanden (Henrik Dam Kristensen):\",\n",
    "    \"Kl. 09:15Troels Lund Poulsen (V):\",\n",
    "    \"Kl. 09:16Formanden (Henrik Dam Kristensen):\",\n",
    "    \"Kl. 09:16Christian Rabjerg Madsen (S):\",\n",
    "    \"Kl. 09:16Formanden (Henrik Dam Kristensen):\",\n",
    "    \"Kl. 09:16René Christensen (DF):\",\n",
    "    \"Kl. 09:17Formanden (Henrik Dam Kristensen):\",\n",
    "    \"Kl. 09:17Christian Rabjerg Madsen (S):\",\n",
    "    \"Kl. 09:18Formanden (Henrik Dam Kristensen):\",\n",
    "    \"Kl. 09:19René Christensen (DF):\",\n",
    "    \"Kl. 09:19Formanden (Henrik Dam Kristensen):\",\n",
    "    \"Kl. 09:19Christian Rabjerg Madsen (S):\",\n",
    "    \"Kl. 09:20Formanden (Henrik Dam Kristensen):\",\n",
    "    \"Kl. 09:20Lisbeth Bech-Nielsen (SF):\",\n",
    "    \"Kl. 09:21Formanden (Henrik Dam Kristensen):\",\n",
    "    \"Kl. 09:21Christian Rabjerg Madsen (S):\",\n",
    "    \"Kl. 09:22Formanden (Henrik Dam Kristensen):\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "80f1048e1ea1460ff79d495a8ef5ec16",
     "grade": false,
     "grade_id": "cell-3374d6d20a9b31ab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. N.3**: Use the matches in the list `matches` to extract the speech of each speaker. You can store the result in a data structure of your choice. For example, you could store each speaker and the corresponding speech as a list of tuples. Finally, print out each speaker and the corresponding speech. Ideally, you should get an output akin to the one in the screenshot shown in the cell below.\n",
    "\n",
    "> - *Hint 1:* You can locate each speaker in the text snippet stored in `parliament_meeting` by writing `match.span()` on each match and subsetting `parliament_meeting` by the indices returned. I.e. the first match returns the tuple `(61, 109)` when computing `matches[0].span()`. This means that the place in the original text where our regex found a match can be found from index `61` to `109` of the text snippet. See the code snippet below\n",
    "```python\n",
    "start_idx, end_idx = matches[0].span()  # (61, 109)\n",
    "print(parliament_meeting[start_idx:end_idx])\n",
    "## Output\n",
    "# Kl. 09:03(Ordfører)Christian Rabjerg Madsen (S):\n",
    "```\n",
    "> - *Hint 2:* To find the first speaker's speech locate the next speaker in the text and extract all text starting from the first speaker until the next speaker. Repeat this for all pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e34907459c4fa6f1c88cf1836c7a318d",
     "grade": false,
     "grade_id": "cell-a0e0a378db5b9a01",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Display example of printout\n",
    "from IPython.display import Image\n",
    "Image(\"parliament-meeting-printout.png\", width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e7d950761780c03ed9479b108189b10",
     "grade": true,
     "grade_id": "N3-test",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
